# **加密货币新闻服务端 \- 设计与实现文档**

## **1\. 概述**

本项目旨在为量化交易系统提供一个轻量级、实时的加密货币新闻服务端。

核心功能包括：

1. **新闻推送**：通过 API 接口接收外部爬虫推送的新闻数据。  
2. **智能分析**：在接收新闻时，立即调用 Gemini API 对新闻进行分析，提取：  
   * 新闻摘要  
   * 市场情绪（利好/利空/中性）  
   * 情绪归一化得分（0.0 \- 1.0）  
   * 提及的相关币种  
3. **新闻查询**：提供 API 接口，用于查询过去1小时内的已分析新闻。  
4. **智能过滤**：查询接口默认只返回新闻摘要。仅在判定为“重大新闻”（情绪得分极高或极低）时，才返回原文。  
5. **市场情绪**：提供 API 接口，用于获取过去1小时内所有新闻的平均情绪得分，作为整体市场情绪的参考。  
6. **自动清理**：系统只保留最近1小时的新闻数据，旧数据会自动清理。

**关于去重**：根据需求，内容相似度去重（\>80%）的逻辑将在**爬虫客户端**实现。本服务端假定收到的所有新闻都是唯一的。

## **2\. 技术栈**

* **后端框架**: FastAPI (高性能, 异步)  
* **数据库**: SQLite (轻量级, 本地文件)  
* **数据模型**: Pydantic  
* **数据库 ORM**: SQLModel (结合了 SQLAlchemy 和 Pydantic)  
* **AI 模型**: Google Gemini API (gemini-2.5-flash-preview-09-2025)  
* **部署**: Docker

## **3\. 数据库设计 (SQLite)**

我们将使用一个单独的表 newsitem 来存储所有新闻数据。

**表名: newsitem**

| 字段名 | 类型 | 描述 |
| :---- | :---- | :---- |
| id | Integer | 主键, 自增 |
| original\_content | Text | 新闻原文 (爬虫推送) |
| source\_url | String | 新闻来源 URL (爬虫推送) |
| received\_at | DateTime | 服务器接收到新闻的时间戳 (自动生成) |
| summary | Text | AI 生成的新闻摘要 |
| sentiment | String | AI 分析的情绪 ('positive', 'negative', 'neutral') |
| sentiment\_score | Float | AI 分析的归一化情绪得分 (0.0: 极度利空, 1.0: 极度利好) |
| mentioned\_coins | String | AI 提取的提及币种 (JSON 字符串列表, e.g., \["BTC", "ETH"\]) |
| is\_major | Boolean | 是否为重大新闻 (根据 sentiment\_score 判定) |

## **4\. API 接口 (Endpoints)**

### **4.1. POST /push\_news**

用于接收爬虫推送的新闻。

* **请求体 (JSON)**:  
  {  
    "content": "这里是新闻的完整内容...",  
    "source\_url": "\[https://example.com/news/123\](https://example.com/news/123)"  
  }

* **处理流程**:  
  1. 接收到请求。  
  2. 调用 gemini\_client.py 中的 analyze\_news\_with\_gemini 函数，将 content 发送给 Gemini API。  
  3. Gemini API 返回结构化 JSON，包含 summary, sentiment, sentiment\_score, mentioned\_coins。  
  4. 根据 sentiment\_score 判断是否为“重大新闻” (is\_major)。  
     * **重大新闻定义**: sentiment\_score \< 0.2 (重大利空) 或 sentiment\_score \> 0.8 (重大利好)。  
  5. 将原文、URL 以及所有 AI 分析结果存入 SQLite 数据库。  
  6. **后台任务**：触发一个后台任务，删除 newsitem 表中 received\_at 早于1小时前的数据。  
* **成功响应 (200 OK)**:  
  {  
    "status": "success",  
    "message": "News received and analyzed.",  
    "id": 123   
  }

### **4.2. GET /get\_news**

查询过去1小时内的所有新闻。

* **请求参数**: 无  
* **处理流程**:  
  1. 查询数据库中 received\_at 在过去1小时内的所有新闻 (WHERE received\_at \>= datetime('now', '-1 hour'))。  
  2. 遍历查询结果。  
  3. 构建响应列表。  
     * 如果 is\_major 为 False，只包含 id, summary, sentiment, sentiment\_score, mentioned\_coins, source\_url, received\_at。  
     * 如果 is\_major 为 True，则额外包含 original\_content。  
* **成功响应 (200 OK)**:  
  \[  
    {  
      "id": 123,  
      "summary": "AI 生成的摘要...",  
      "sentiment": "positive",  
      "sentiment\_score": 0.85,  
      "mentioned\_coins": \["BTC", "SOL"\],  
      "source\_url": "\[https://example.com/news/123\](https://example.com/news/123)",  
      "received\_at": "2025-10-29T17:01:00.000Z",  
      "is\_major": true,  
      "original\_content": "这是一条重大利好新闻的原文..."  
    },  
    {  
      "id": 124,  
      "summary": "另一条新闻的摘要...",  
      "sentiment": "neutral",  
      "sentiment\_score": 0.5,  
      "mentioned\_coins": \["ETH"\],  
      "source\_url": "\[https://example.com/news/124\](https://example.com/news/124)",  
      "received\_at": "2025-10-29T17:05:00.000Z",  
      "is\_major": false  
    }  
  \]

### **4.3. GET /get\_new\_detail/:id**

获取新闻详情。

* **请求参数**: 新闻id
* **处理流程**:
  
查询新闻数据吐出详情数据


### **4.3. GET /get\_market\_sentiment**

获取当前（1小时内）的整体市场情绪。

* **请求参数**: 无  
* **处理流程**:  
  1. 查询数据库中过去1小时内所有新闻的 sentiment\_score 字段。  
  2. 计算所有得分的**平均值**。  
  3. 如果过去1小时没有新闻，返回中性值 0.5。
  4. 输出最大值和最小值，输出对应新闻id
* **成功响应 (200 OK)**:  
  {  
    "market\_sentiment\_normalized": 0.62,  
    "news\_count": 5  
  }

## **5\. 核心逻辑**

### **5.1. AI 分析 (deepseek)**

我们将使用 deepseek API 的 JSON 模式，以确保返回的数据格式始终一致。

* **模型**: deepseek-chat  
* **系统提示 (System Prompt)**:  
  你是一个专业的加密货币金融分析师。请分析以下新闻内容。  
  你需要提供：  
  1\.  'summary': 对新闻的简明中文摘要。  
  2\.  'sentiment': 判断新闻情绪是 'positive' (利好), 'negative' (利空), 还是 'neutral' (中性)。  
  3\.  'sentiment\_score': 情绪的归一化得分，0.0代表极度利空，1.0代表极度利好，0.5代表中性。  
  4\.  'mentioned\_coins': 提及的具体加密货币代码（例如 BTC, ETH, SOL）。如果没有，返回空列表。  
  请严格按照请求的 JSON 格式输出。

* **JSON Schema (用于约束输出)**:  
  {  
    "type": "OBJECT",  
    "properties": {  
      "summary": { "type": "STRING" },  
      "sentiment": { "type": "STRING" },  
      "sentiment_score": { "type": "NUMBER" },  
      "mentioned_coins": {  
        "type": "ARRAY",  
        "items": { "type": "STRING" }  
      }  
    }  
  }

### **5.2. 数据清理**

数据清理将通过 FastAPI 的 BackgroundTasks 实现。在每次 POST /push\_news 成功后，会异步触发一个清理任务，删除1小时前的数据，确保数据库的轻量和高效。

## **6\. 部署 (Docker)**

项目包含一个 Dockerfile，可以轻松构建和部署。

1. **构建镜像**:  
   docker build \-t crypto-news-server .

2. **运行容器**:  
   docker run \-d \-p 8000:8000 \-v ./db:/app/db \--name news-server crypto-news-server

   * \-p 8000:8000: 将容器的 8000 端口映射到主机的 8000 端口。  
   * \-v ./db:/app/db: **重要**: 将本地的 ./db 目录挂载到容器的 /app/db 目录。这将使 SQLite 数据库文件 (news.db) 持久化保存在主机上，避免容器重启导致数据丢失。

## **7\. 爬虫端建议 (去重)**

根据需求，爬虫端在推送新闻到本服务前，应自行实现内容去重。

* **建议方法**:  
  1. 爬虫端维护一个最近1-2小时内已推送新闻的 (content, source) 缓存。  
  2. 当爬取到新新闻时，使用 difflib (Python 内置库) 或 fuzzywuzzy 等库，将其内容与缓存中的内容进行相似度比较。  
  3. difflib.SequenceMatcher(None, new\_content, cached\_content).ratio() 可以返回一个 0-1 的相似度得分。  
  4. 如果相似度 \> 0.8 (80%)，则判定为重复内容，**不再推送**到本服务端。
  5. 爬虫使用webdriver下的chrome.py 操作浏览器爬取指定用户的推特内容，方法如下：
  ```python
  def get_content(driver,account_url_list ):
    """模拟微信视频号直播页面请求"""
    time.sleep(2)
    for url in account_url_list:
        print("正在抓取账号内容：", url)
        try:
            # 目标URL
            driver.get(url)
            
            # 等待页面加载
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, 'section[role="region"]'))
            )
            elments = driver.find_elements(By.CSS_SELECTOR, 'section[role="region"] div[data-testid="cellInnerDiv"]')
            content = ""
            for elment in elments:
                if "Premium" in elment.text:
                    continue
                content += elment.text + "\n"
            return content
            
        except Exception as e:
            print(f"发生错误: {e}")
            return None
    def login():
        global dirver_handler
        dirver_handler.get("https://x.com/")
        WebDriverWait(driver, 600).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, 'button[aria-label="Account menu"]'))
        )

  ```

  